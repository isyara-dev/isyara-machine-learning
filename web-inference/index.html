<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Deteksi Bahasa Isyarat</title>
  <style>
    body {
      margin: 0;
      background-color: #111;
      color: white;
      font-family: Arial, sans-serif;
      text-align: center;
    }
    
    h1 {
      margin-top: 20px;
    }
    
    canvas {
      position: absolute;
      top: 80px;
      left: 50%;
      width: 640px;
      height: 480px;
      border-radius: 10px;
      transform: scale(-1, 1) translateX(50%);
    }

    #prediction {
      position: absolute;
      top: 100px;
      left: 50%;
      transform: translateX(-50%);
      font-size: 24px;
      font-weight: bold;
      color: gold;
      background-color: rgba(0, 0, 0, 0.5);
      padding: 8px 16px;
      border-radius: 10px;
      z-index: 10;
    }

    #confidence {
      position: absolute;
      top: 145px;
      left: 50%;
      transform: translateX(-50%);
      font-size: 16px;
      color: white;
      background-color: rgba(0, 0, 0, 0.5);
      padding: 4px 8px;
      border-radius: 5px;
      z-index: 10;
    }
  </style>
</head>
<body>
  <h1>Deteksi Bahasa Isyarat Real-time</h1>
  <video id="video" autoplay playsinline style="display: none;"></video>
  <canvas id="canvas"></canvas>
  <div id="prediction">Predicted: -</div>
  <div id="confidence">Confidence: -</div>

  <!-- MediaPipe & TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.14.0/dist/tf.min.js"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const predictionDiv = document.getElementById('prediction');
    const confidenceDiv = document.getElementById('confidence');

    canvas.width = 640;
    canvas.height = 480;

    let tfModel = null;
    const labelMap = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.split('');
    const CONFIDENCE_THRESHOLD = 0.7;

    async function loadModel() {
      try {
        tfModel = await tf.loadGraphModel('model.json');
        console.log("âœ… Model loaded successfully!");
      } catch (error) {
        console.error("âŒ Failed to load model:", error);
        predictionDiv.textContent = "Error loading model";
      }
    }

    function normalizeLandmarks(landmarks, wrist) {
      return landmarks.map(lm => [lm.x - wrist.x, lm.y - wrist.y, lm.z - wrist.z]);
    }

    function processLandmarks(landmarks) {
      let features = [];

      if (landmarks.length === 1) {
        console.log("ðŸ› ï¸ Only one hand detected, assigning as right hand.");
        
        // Isi left hand dengan 0 terlebih dahulu
        const leftHand = Array(63).fill(0);
        features.push(...leftHand);
        
        // Lanjutkan dengan right hand
        const rightHand = normalizeLandmarks(landmarks[0], landmarks[0][0]);
        rightHand.forEach(coord => features.push(...coord));

      } else if (landmarks.length === 2) {
        const sortedHands = landmarks.sort((a, b) => a[0].x - b[0].x);
        const leftHand = normalizeLandmarks(sortedHands[0], sortedHands[0][0]);
        const rightHand = normalizeLandmarks(sortedHands[1], sortedHands[1][0]);

        leftHand.forEach(coord => features.push(...coord));
        rightHand.forEach(coord => features.push(...coord));
      }

      // Jika jumlah fitur tidak sesuai (harus 126), isi semua dengan 0
      if (features.length !== 126) {
        console.warn("âš ï¸ Feature length is not 126. Setting all features to 0.");
        features = Array(126).fill(0);
      }

      console.log("Normalized features:", features);
      return tf.tensor2d([features], [1, 126]);
    }

    const hands = new Hands({ locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}` });
    hands.setOptions({ maxNumHands: 2, modelComplexity: 1, minDetectionConfidence: 0.7, minTrackingConfidence: 0.5, smoothLandmarks: true });
    
    hands.onResults(async (results) => {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      if (results.multiHandLandmarks && tfModel) {
        const inputTensor = processLandmarks(results.multiHandLandmarks);

        if (inputTensor) {
          try {
            const output = tfModel.predict(inputTensor);
            const predictions = output.arraySync()[0];

            const maxPrediction = Math.max(...predictions);
            const predictedClass = predictions.indexOf(maxPrediction);
            const confidence = (maxPrediction * 100).toFixed(1);

            if (maxPrediction > CONFIDENCE_THRESHOLD) {
              predictionDiv.textContent = `Predicted: ${labelMap[predictedClass]}`;
              confidenceDiv.textContent = `Confidence: ${confidence}%`;
            } else {
              predictionDiv.textContent = "Predicted: -";
              confidenceDiv.textContent = "Confidence: -";
            }

            inputTensor.dispose();
            tf.dispose(output);
          } catch (error) {
            console.error("Prediction error:", error);
          }
        }
      } else {
        predictionDiv.textContent = "Predicted: -";
        confidenceDiv.textContent = "Confidence: -";
      }
    });

    const camera = new Camera(video, { 
      onFrame: async () => { 
        await hands.send({ image: canvas }); 
      }, 
      width: 640, 
      height: 480 
    });

    async function startApp() {
      await loadModel();
      try {
        await camera.start();
      } catch (error) {
        console.error("Camera error:", error);
        predictionDiv.textContent = "Error accessing camera";
      }
    }

    startApp();
  </script>
</body>
</html>
